{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>david</td>\n",
       "      <td>92</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laura</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanjay</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wei</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jeff</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aamir</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>venkat</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>virat</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arthur</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paul</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  math  cs\n",
       "0   david    92  98\n",
       "1   laura    56  68\n",
       "2  sanjay    88  81\n",
       "3     wei    70  80\n",
       "4    jeff    80  83\n",
       "5   aamir    49  52\n",
       "6  venkat    65  66\n",
       "7   virat    35  30\n",
       "8  arthur    66  68\n",
       "9    paul    67  73"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test_score.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   name    10 non-null     object\n",
      " 1   math    10 non-null     int64 \n",
      " 2   cs      10 non-null     int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01773624])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(df[['math']], df['cs'])\n",
    "\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9152193111569176"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 0.9891800000000002, b 0.013980000000000001, cost 5199.1, iteration 0\n",
      "m 1.0416176032, b 0.0147417592, cost 46.3330473650399, iteration 1\n",
      "m 1.0443971065873279, b 0.014802799669408, cost 31.852649863558305, iteration 2\n",
      "m 1.0445441606668626, b 0.014826693765467417, cost 31.811952059367805, iteration 3\n",
      "m 1.0445516647187705, b 0.014848618440205038, cost 31.811832943358482, iteration 4\n",
      "m 1.0445517710206773, b 0.014870438475874223, cost 31.81182786237329, iteration 5\n",
      "m 1.0445514851602624, b 0.0148922527273428, cost 31.811823101960222, iteration 6\n",
      "m 1.0445511785140886, b 0.014914066435056226, cost 31.81181834255699, iteration 7\n",
      "m 1.0445508707693771, b 0.01493587987682099, cost 31.811813583265543, iteration 8\n",
      "m 1.0445505629697767, b 0.014957693067366749, cost 31.811808824083364, iteration 9\n",
      "m 1.044550255170612, b 0.014979506007477059, cost 31.811804065010467, iteration 10\n",
      "m 1.0445499473748168, b 0.015001318697196186, cost 31.81179930604682, iteration 11\n",
      "m 1.0445496395825458, b 0.015023131136529195, cost 31.811794547192434, iteration 12\n",
      "m 1.0445493317938075, b 0.015044943325479078, cost 31.81178978844727, iteration 13\n",
      "m 1.0445490240086022, b 0.015066755264048713, cost 31.811785029811393, iteration 14\n",
      "m 1.04454871622693, b 0.015088566952240978, cost 31.81178027128471, iteration 15\n",
      "m 1.0445484084487908, b 0.015110378390058745, cost 31.811775512867314, iteration 16\n",
      "m 1.0445481006741846, b 0.015132189577504887, cost 31.811770754559184, iteration 17\n",
      "m 1.0445477929031113, b 0.01515400051458228, cost 31.811765996360236, iteration 18\n",
      "m 1.0445474851355707, b 0.015175811201293797, cost 31.811761238270567, iteration 19\n",
      "m 1.044547177371563, b 0.015197621637642314, cost 31.8117564802901, iteration 20\n",
      "m 1.0445468696110882, b 0.015219431823630702, cost 31.811751722418904, iteration 21\n",
      "m 1.0445465618541463, b 0.015241241759261838, cost 31.81174696465691, iteration 22\n",
      "m 1.0445462541007369, b 0.015263051444538593, cost 31.811742207004155, iteration 23\n",
      "m 1.0445459463508602, b 0.015284860879463841, cost 31.81173744946062, iteration 24\n",
      "m 1.0445456386045162, b 0.015306670064040457, cost 31.811732692026307, iteration 25\n",
      "m 1.0445453308617048, b 0.015328478998271312, cost 31.811727934701214, iteration 26\n",
      "m 1.0445450231224258, b 0.015350287682159283, cost 31.81172317748536, iteration 27\n",
      "m 1.0445447153866794, b 0.015372096115707242, cost 31.811718420378693, iteration 28\n",
      "m 1.0445444076544654, b 0.015393904298918064, cost 31.811713663381234, iteration 29\n",
      "m 1.044544099925784, b 0.015415712231794622, cost 31.811708906493, iteration 30\n",
      "m 1.0445437922006349, b 0.015437519914339788, cost 31.811704149713975, iteration 31\n",
      "m 1.0445434844790182, b 0.015459327346556438, cost 31.81169939304415, iteration 32\n",
      "m 1.0445431767609337, b 0.015481134528447443, cost 31.81169463648351, iteration 33\n",
      "m 1.0445428690463816, b 0.01550294146001568, cost 31.8116898800321, iteration 34\n",
      "m 1.0445425613353618, b 0.01552474814126402, cost 31.811685123689838, iteration 35\n",
      "m 1.044542253627874, b 0.015546554572195332, cost 31.811680367456837, iteration 36\n",
      "m 1.0445419459239182, b 0.015568360752812498, cost 31.811675611332994, iteration 37\n",
      "m 1.0445416382234949, b 0.015590166683118389, cost 31.811670855318336, iteration 38\n",
      "m 1.0445413305266036, b 0.015611972363115874, cost 31.81166609941286, iteration 39\n",
      "m 1.0445410228332441, b 0.015633777792807828, cost 31.811661343616585, iteration 40\n",
      "m 1.0445407151434167, b 0.015655582972197123, cost 31.811656587929505, iteration 41\n",
      "m 1.0445404074571212, b 0.015677387901286637, cost 31.811651832351572, iteration 42\n",
      "m 1.0445400997743577, b 0.01569919258007924, cost 31.811647076882846, iteration 43\n",
      "m 1.044539792095126, b 0.015720997008577806, cost 31.811642321523266, iteration 44\n",
      "m 1.0445394844194262, b 0.015742801186785206, cost 31.811637566272857, iteration 45\n",
      "m 1.044539176747258, b 0.015764605114704313, cost 31.81163281113166, iteration 46\n",
      "m 1.0445388690786215, b 0.015786408792338003, cost 31.81162805609962, iteration 47\n",
      "m 1.044538561413517, b 0.01580821221968915, cost 31.811623301176713, iteration 48\n",
      "m 1.0445382537519439, b 0.015830015396760624, cost 31.81161854636297, iteration 49\n",
      "m 1.0445379460939026, b 0.0158518183235553, cost 31.811613791658388, iteration 50\n",
      "m 1.044537638439393, b 0.01587362100007605, cost 31.811609037062983, iteration 51\n",
      "m 1.0445373307884147, b 0.015895423426325744, cost 31.811604282576713, iteration 52\n",
      "m 1.0445370231409679, b 0.015917225602307256, cost 31.81159952819962, iteration 53\n",
      "m 1.0445367154970526, b 0.015939027528023463, cost 31.81159477393166, iteration 54\n",
      "m 1.0445364078566688, b 0.015960829203477234, cost 31.811590019772854, iteration 55\n",
      "m 1.0445361002198164, b 0.015982630628671442, cost 31.811585265723178, iteration 56\n",
      "m 1.044535792586495, b 0.016004431803608964, cost 31.811580511782672, iteration 57\n",
      "m 1.0445354849567052, b 0.016026232728292667, cost 31.811575757951275, iteration 58\n",
      "m 1.0445351773304468, b 0.016048033402725426, cost 31.81157100422902, iteration 59\n",
      "m 1.0445348697077192, b 0.016069833826910112, cost 31.811566250615925, iteration 60\n",
      "m 1.0445345620885231, b 0.016091634000849602, cost 31.811561497111924, iteration 61\n",
      "m 1.0445342544728582, b 0.016113433924546765, cost 31.81155674371708, iteration 62\n",
      "m 1.0445339468607242, b 0.01613523359800447, cost 31.81155199043136, iteration 63\n",
      "m 1.0445336392521212, b 0.016157033021225595, cost 31.81154723725477, iteration 64\n",
      "m 1.0445333316470493, b 0.01617883219421301, cost 31.811542484187278, iteration 65\n",
      "m 1.0445330240455084, b 0.01620063111696959, cost 31.811537731228913, iteration 66\n",
      "m 1.0445327164474982, b 0.016222429789498203, cost 31.811532978379674, iteration 67\n",
      "m 1.0445324088530192, b 0.01624422821180173, cost 31.811528225639552, iteration 68\n",
      "m 1.044532101262071, b 0.016266026383883032, cost 31.811523473008528, iteration 69\n",
      "m 1.0445317936746534, b 0.016287824305744988, cost 31.81151872048663, iteration 70\n",
      "m 1.0445314860907668, b 0.016309621977390467, cost 31.811513968073832, iteration 71\n",
      "m 1.044531178510411, b 0.016331419398822346, cost 31.81150921577014, iteration 72\n",
      "m 1.0445308709335857, b 0.016353216570043492, cost 31.811504463575552, iteration 73\n",
      "m 1.044530563360291, b 0.01637501349105678, cost 31.811499711490075, iteration 74\n",
      "m 1.044530255790527, b 0.016396810161865078, cost 31.81149495951366, iteration 75\n",
      "m 1.0445299482242936, b 0.016418606582471264, cost 31.811490207646354, iteration 76\n",
      "m 1.0445296406615905, b 0.016440402752878207, cost 31.811485455888132, iteration 77\n",
      "m 1.0445293331024181, b 0.016462198673088783, cost 31.811480704239013, iteration 78\n",
      "m 1.0445290255467763, b 0.01648399434310586, cost 31.811475952698995, iteration 79\n",
      "m 1.0445287179946647, b 0.01650578976293231, cost 31.81147120126803, iteration 80\n",
      "m 1.0445284104460835, b 0.016527584932571004, cost 31.81146644994618, iteration 81\n",
      "m 1.0445281029010325, b 0.016549379852024815, cost 31.811461698733396, iteration 82\n",
      "m 1.044527795359512, b 0.016571174521296615, cost 31.811456947629672, iteration 83\n",
      "m 1.0445274878215214, b 0.016592968940389273, cost 31.81145219663505, iteration 84\n",
      "m 1.0445271802870615, b 0.01661476310930567, cost 31.81144744574947, iteration 85\n",
      "m 1.0445268727561314, b 0.016636557028048667, cost 31.811442694972982, iteration 86\n",
      "m 1.0445265652287314, b 0.01665835069662114, cost 31.811437944305567, iteration 87\n",
      "m 1.0445262577048617, b 0.016680144115025965, cost 31.811433193747185, iteration 88\n",
      "m 1.0445259501845219, b 0.016701937283266008, cost 31.811428443297885, iteration 89\n",
      "m 1.044525642667712, b 0.016723730201344142, cost 31.811423692957646, iteration 90\n",
      "m 1.0445253351544324, b 0.01674552286926324, cost 31.811418942726483, iteration 91\n",
      "m 1.0445250276446825, b 0.01676731528702617, cost 31.81141419260433, iteration 92\n",
      "m 1.0445247201384624, b 0.01678910745463581, cost 31.811409442591266, iteration 93\n",
      "m 1.0445244126357722, b 0.016810899372095022, cost 31.811404692687223, iteration 94\n",
      "m 1.0445241051366119, b 0.016832691039406687, cost 31.81139994289224, iteration 95\n",
      "m 1.0445237976409811, b 0.01685448245657367, cost 31.81139519320631, iteration 96\n",
      "m 1.0445234901488802, b 0.016876273623598847, cost 31.811390443629406, iteration 97\n",
      "m 1.0445231826603092, b 0.016898064540485088, cost 31.81138569416154, iteration 98\n",
      "m 1.0445228751752675, b 0.01691985520723526, cost 31.81138094480272, iteration 99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0445228751752675, 0.01691985520723526)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_descent(x,y):\n",
    "    m_curr = b_curr = 0\n",
    "    iterations = 100\n",
    "    n = len(x)\n",
    "    learning_rate = 0.0001\n",
    "    cost_previous = 0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
    "        md = -(2/n)*sum(x*(y-y_predicted))\n",
    "        bd = -(2/n)*sum(y-y_predicted)\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        if math.isclose(cost, cost_previous, rel_tol=1e-20):\n",
    "            break\n",
    "        cost_previous = cost\n",
    "        print(\"m {}, b {}, cost {}, iteration {}\".format(m_curr,b_curr,cost, i))\n",
    "\n",
    "    return m_curr, b_curr\n",
    "\n",
    "x = np.array(df.math)\n",
    "y = np.array(df.cs)\n",
    "\n",
    "gradient_descent(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code by sir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_using_sklean():\n",
    "    df = pd.read_csv(\"test_score.csv\")\n",
    "    r = LinearRegression()\n",
    "    r.fit(df[['math']],df.cs)\n",
    "    return r.coef_, r.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gradient_descent(x,y):\n",
    "    m_curr = 0\n",
    "    b_curr = 0\n",
    "    iterations = 10\n",
    "    n = len(x)\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    cost_previous = 0\n",
    "\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = (1/n)*sum([value**2 for value in (y-y_predicted)])\n",
    "        md = -(2/n)*sum(x*(y-y_predicted))\n",
    "        bd = -(2/n)*sum(y-y_predicted)\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        if math.isclose(cost, cost_previous, rel_tol=1e-20):\n",
    "            break\n",
    "        cost_previous = cost\n",
    "        print (\"m {}, b {}, cost {}, iteration {}\".format(m_curr,b_curr,cost, i))\n",
    "\n",
    "    return m_curr, b_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 0.9891800000000002, b 0.013980000000000001, cost 5199.1, iteration 0\n",
      "m 1.0416176032, b 0.0147417592, cost 46.3330473650399, iteration 1\n",
      "m 1.0443971065873279, b 0.014802799669408, cost 31.852649863558305, iteration 2\n",
      "m 1.0445441606668626, b 0.014826693765467417, cost 31.811952059367805, iteration 3\n",
      "m 1.0445516647187705, b 0.014848618440205038, cost 31.811832943358482, iteration 4\n",
      "m 1.0445517710206773, b 0.014870438475874223, cost 31.81182786237329, iteration 5\n",
      "m 1.0445514851602624, b 0.0148922527273428, cost 31.811823101960222, iteration 6\n",
      "m 1.0445511785140886, b 0.014914066435056226, cost 31.81181834255699, iteration 7\n",
      "m 1.0445508707693771, b 0.01493587987682099, cost 31.811813583265543, iteration 8\n",
      "m 1.0445505629697767, b 0.014957693067366749, cost 31.811808824083364, iteration 9\n",
      "Using gradient descent function: Coef 1.0445505629697767 Intercept 0.014957693067366749\n",
      "Using sklearn: Coef [1.01773624] Intercept 1.9152193111569176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"test_score.csv\")\n",
    "    x = np.array(df.math)\n",
    "    y = np.array(df.cs)\n",
    "\n",
    "    m, b = gradient_descent(x,y)\n",
    "    print(\"Using gradient descent function: Coef {} Intercept {}\".format(m, b))\n",
    "\n",
    "    m_sklearn, b_sklearn = predict_using_sklean()\n",
    "    print(\"Using sklearn: Coef {} Intercept {}\".format(m_sklearn,b_sklearn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('minimal_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b939c7e6ec3c1099ad698f283bbd73d8b37067c80752770296ee97f845b4c5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
